# -*- coding: utf-8 -*-
"""Loading_Toon_Models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mYWiTeWRh7YfiLFblNYDjCtPtWCl5GVt

### Loading the Generator
This notebook will outline the process of loading a trained generator. We will start by copying the architecture of the generator from our main training notebook. We will then update the model's states using the state dictionary that can be downloaded at the end of training.
"""

# importing
import torch
import torch.nn as nn
import matplotlib.pyplot as plt

# The generator architecture and related classes.
class G_Unit(nn.Module):
    def __init__(self, in_channels, out_channels,  kernel_size=4, stride=2,
                 padding=1, **kwargs): # **kwargs implemented here because additional arguments(lr and betas) will be added during training.
        super(G_Unit, self).__init__(**kwargs)
        # Creating the generator unit. Using nn.Sequential for readability.
        self.block = nn.Sequential(nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding),
                                nn.BatchNorm2d(out_channels), # Using batch normalization for better results.
                                nn.ReLU()
                                )

    def forward(self, X):
        output = self.block(X)
        return output

G_arch = nn.Sequential( # Using nn.Sequential for readability.
    G_Unit(in_channels=100, out_channels=2048),      # The first layer takes a tensor of 100 channels(initialized during training) and outputs
    G_Unit(in_channels=1024*2, out_channels=1024*2), # 2048 channels(64*32 decreased from 64*64 because of computational limitations). The second to sixth layer
    G_Unit(in_channels=1024*2, out_channels=1024),   # mostly decrease the output channels gradually for optimal learning. These, along with the initial output
    G_Unit(in_channels=1024, out_channels=512),      # could be increased(more neurons) for better and more detail oriented learning.
    G_Unit(in_channels=512, out_channels=256),
    G_Unit(in_channels=256, out_channels=128),

    nn.ConvTranspose2d(in_channels=128, out_channels=3, kernel_size=4, stride=2, padding=1),
    nn.Tanh() # Tanh limits the range from -1 to 1, ideal for image related data.
    )

# The model parameters could be updated using the state dictionary(file path will be different on your local machine).
gen_path = '/content/toonsnet_G3.pth' # path to uploaded state dictionary.

!ls -lh {gen_path}  # Checking file size and permissions.
#!unzip -t {gen_path} # Uncomment this line if file unzipping needed.

G_arch.load_state_dict(torch.load(gen_path)) # Loading the state dictionary.
G_arch.eval() # Setting the model to evaluation mode.

# We can see the generator in action by feeding it random data. Will be running this on cpu.

Z = torch.normal(0, 1, size=(1, 100, 1, 1), device='cpu')
fake_x = G_arch(Z).permute(0, 2, 3, 1) / 2 + 0.5 # getting the image and rearranging the dimensions/modifying vals.
print(fake_x.shape) # Checking shape to confirm batch size, image resolution, and channels.
plt.figure(figsize=(1,1))
plt.imshow(fake_x[0].cpu().detach().numpy()) # Showing the image.

"""This model was trained on the A100 gpu for a limited number of epochs(over 2.5 hours). Despite the limitation, the outputs are great as small features like the nose and mouth of the toons are visible. Higher input image resolutions, bigger batch sizes, more model neurons, and greater number of epochs could potentially lead to even better results, however greater computation and wait times would likely be needed."""